{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from geopy.geocoders import Nominatim\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Samples/police_nationale.json', encoding='UTF-8') as f: \n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping\n",
    "\n",
    "comments_list = []\n",
    "dates_list = []\n",
    "name_service = []\n",
    "address_service = []\n",
    "region_list = []\n",
    "\n",
    "for administration in data.keys():\n",
    "    for link in range(len(data[administration])):\n",
    "        # initialiser le webdriver\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(data[administration][link])\n",
    "\n",
    "        # refuser les cookies\n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME, 'VfPpkd-LgbsSe.VfPpkd-LgbsSe-OWXEXe-k8QpJ.VfPpkd-LgbsSe-OWXEXe-dgl2Hf.nCP5yc.AjY5Oe.DuMIQc.LQeN7.Nc7WLe').click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # cliquer sur le bouton avis\n",
    "        try:\n",
    "            driver.find_elements(By.CLASS_NAME, 'hh2c6')[1].click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # faire défiler la page pour charger tous les commentaires\n",
    "        try:\n",
    "            scrollable_div = driver.find_element(By.CSS_SELECTOR, \"div.m6QErb.DxyBCb.kA9KIf.dS8AEf\")\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        old_freq = 0\n",
    "        while True:\n",
    "            driver.execute_script(\n",
    "                'arguments[0].scrollTop = arguments[0].scrollHeight',\n",
    "                scrollable_div\n",
    "            )\n",
    "            time.sleep(3)\n",
    "            freq = scrollable_div.text.count('Partager\\n')\n",
    "            if freq == old_freq:\n",
    "                break\n",
    "            old_freq = freq\n",
    "        \n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME,'w8nwRe.kyuRq').click()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            comments = driver.find_elements(By.CSS_SELECTOR, 'div.GHT2ce > div > div.MyEned > span.wiI7pd')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        comments_list.append([comments[elt].text for elt in range(len(comments))])\n",
    "        \n",
    "        for indice in range(len(comments)):\n",
    "            region_list.append(administration.split(\"région\")[-1])\n",
    "        \n",
    "        try:\n",
    "            dates = driver.find_elements(By.CLASS_NAME,'rsqaWe')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        dates_list.append([dates[i].text for i in range(len(comments))])\n",
    "        \n",
    "        try:\n",
    "            driver.find_element(By.CLASS_NAME,'Gpq6kf.fontTitleSmall').click()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            name_service.append(driver.find_element(By.CLASS_NAME,'DUwDvf.fontHeadlineLarge').accessible_name)\n",
    "            address_service.append(driver.find_element(By.CLASS_NAME,'Io6YTe.fontBodyMedium').text)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les listes de services et d'adresses\n",
    "\n",
    "name_service_list = []\n",
    "address_service_list = []\n",
    "\n",
    "for index in range(len(comments_list)):\n",
    "    for elt in range(len(comments_list[index])):\n",
    "        name_service_list.append(name_service[index])\n",
    "        address_service_list.append(address_service[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer la liste des commentaires\n",
    "new_comments_list = []\n",
    "for index in range(len(comments_list)):\n",
    "    for elt in comments_list[index]:\n",
    "        new_comments_list.append(elt)\n",
    "        \n",
    "# Récupérer la liste des dates\n",
    "new_dates_list = []\n",
    "for index in range(len(dates_list)):\n",
    "    for elt in dates_list[index]:\n",
    "        new_dates_list.append(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame des données\n",
    "\n",
    "dict_text = {\n",
    "    'Administration': name_service_list,\n",
    "    'Avis': new_comments_list,\n",
    "    'Adresses': address_service_list,\n",
    "    'Régions': region_list,\n",
    "    'Dates': new_dates_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./Samples/dataset_police_nationale.csv\", sep=',', encoding='UTF-8', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de récupération des coordonnées géographiques des régions\n",
    "def trouver_coordonnees_geographiques(region):\n",
    "    geolocator = Nominatim(user_agent='my_app')\n",
    "    location = geolocator.geocode(region + ', France')\n",
    "    \n",
    "    if location is not None:\n",
    "        latitude = location.latitude\n",
    "        longitude = location.longitude\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction trouver_coordonnees_geographiques()\n",
    "lat = []\n",
    "long = []\n",
    "for elt in df[\"Régions\"]:\n",
    "    latitude, longitude = trouver_coordonnees_geographiques(f\"'{elt}'\")\n",
    "\n",
    "    if latitude is not None and longitude is not None:\n",
    "        lat.append(latitude)\n",
    "        long.append(longitude)\n",
    "    else:\n",
    "        print(f\"Impossible de trouver les coordonnées géographiques de la région {elt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du DataFrame des données avec les coordonnées géographiques des régions\n",
    "\n",
    "new_dict_text = {\n",
    "    'Administration': name_service_list,\n",
    "    'Avis': new_comments_list,\n",
    "    'Adresses': address_service_list,\n",
    "    'Dates': new_dates_list,\n",
    "    'Régions': region_list,\n",
    "    'Latitudes': lat,\n",
    "    'Longitudes': long\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"./Samples/dataset_police_nationale.csv\", sep=',', encoding='UTF-8', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
